<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Patrick Feeney - papers</title><link href="https://patrickfeeney.github.io/" rel="alternate"></link><link href="https://patrickfeeney.github.io/feeds/papers.atom.xml" rel="self"></link><id>https://patrickfeeney.github.io/</id><updated>2024-03-15T10:00:00-05:00</updated><entry><title>A Neurosymbolic Cognitive Architecture Framework for Handling Novelties in Open Worlds</title><link href="https://patrickfeeney.github.io/a-neurosymbolic-cognitive-architecture-framework-for-handling-novelties-in-open-worlds.html" rel="alternate"></link><published>2024-03-15T10:00:00-05:00</published><updated>2024-03-15T10:00:00-05:00</updated><author><name>Patrick Feeney</name></author><id>tag:patrickfeeney.github.io,2024-03-15:/a-neurosymbolic-cognitive-architecture-framework-for-handling-novelties-in-open-worlds.html</id><summary type="html">&lt;p&gt;Published in &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S000437022400047X"&gt;Artificial Intelligence&lt;/a&gt;. &lt;a href="https://patrickfeeney.github.io/papers/Revised_v2_0__AIJ_23__A_Neurosymbolic_Cognitive_Architecture_for_Handling_Novelties_in_Open_Worlds.pdf"&gt;PDF&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;"Open world" environments are those in which novel objects, agents, events, and more can appear and contradict previous understandings of the environment. This contradicts the "closed world" assumption used in most AI research, where the environment is assumed to be fully understood and unchanging. The …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Published in &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S000437022400047X"&gt;Artificial Intelligence&lt;/a&gt;. &lt;a href="https://patrickfeeney.github.io/papers/Revised_v2_0__AIJ_23__A_Neurosymbolic_Cognitive_Architecture_for_Handling_Novelties_in_Open_Worlds.pdf"&gt;PDF&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;"Open world" environments are those in which novel objects, agents, events, and more can appear and contradict previous understandings of the environment. This contradicts the "closed world" assumption used in most AI research, where the environment is assumed to be fully understood and unchanging. The types of environments AI agents can be deployed in are limited by the inability to handle the novelties that occur in open world environments. This paper presents a novel cognitive architecture framework to handle open-world novelties. This framework combines symbolic planning, counterfactual reasoning, reinforcement learning, and deep computer vision to detect and accommodate novelties. We introduce general algorithms for exploring open worlds using inference and machine learning methodologies to facilitate novelty accommodation. The ability to detect and accommodate novelties allows agents built on this framework to successfully complete tasks despite a variety of novel changes to the world. Both the framework components and the entire system are evaluated in Minecraft-like simulated environments. Our results indicate that agents are able to efficiently complete tasks while accommodating "concealed novelties: not shared with the architecture development team.&lt;/p&gt;</content><category term="papers"></category><category term="news"></category></entry><entry><title>SINCERE: Supervised Information Noise-Contrastive Estimation REvisited</title><link href="https://patrickfeeney.github.io/sincere-supervised-information-noise-contrastive-estimation-revisited.html" rel="alternate"></link><published>2024-03-11T10:00:00-05:00</published><updated>2024-03-11T10:00:00-05:00</updated><author><name>Patrick Feeney</name></author><id>tag:patrickfeeney.github.io,2024-03-11:/sincere-supervised-information-noise-contrastive-estimation-revisited.html</id><summary type="html">&lt;p&gt;Under review for ICML 2024.
&lt;a href="https://arxiv.org/abs/2309.14277"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation.
Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels.
However …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Under review for ICML 2024.
&lt;a href="https://arxiv.org/abs/2309.14277"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The information noise-contrastive estimation (InfoNCE) loss function provides the basis of many self-supervised deep learning methods due to its strong empirical results and theoretic motivation.
Previous work suggests a supervised contrastive (SupCon) loss to extend InfoNCE to learn from available class labels.
However, in this work we find that the prior SupCon loss formulation has questionable justification because it can encourage some images from the same class to repel one another in the learned embedding space.
We propose the Supervised InfoNCE REvisited (SINCERE) loss as a theoretically-justified supervised extension of InfoNCE that never causes images from the same class to repel one another.
Experiments show that SINCERE leads to better separation of embeddings from different classes while delivering competitive classification accuracy for supervised and transfer learning.
We further show an information-theoretic bound that relates SINCERE loss to the symmeterized KL divergence between data-generating distributions for a target class and all other classes. &lt;/p&gt;</content><category term="papers"></category><category term="news"></category></entry><entry><title>NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds</title><link href="https://patrickfeeney.github.io/novelcraft-a-dataset-for-novelty-detection-and-discovery-in-open-worlds.html" rel="alternate"></link><published>2022-06-23T10:00:00-05:00</published><updated>2022-06-23T10:00:00-05:00</updated><author><name>Patrick Feeney</name></author><id>tag:patrickfeeney.github.io,2022-06-23:/novelcraft-a-dataset-for-novelty-detection-and-discovery-in-open-worlds.html</id><summary type="html">&lt;p&gt;Published in &lt;a href="https://openreview.net/forum?id=4eL6z9ziw7"&gt;TMLR&lt;/a&gt;.
&lt;a href="https://arxiv.org/abs/2206.11736"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Published in &lt;a href="https://openreview.net/forum?id=4eL6z9ziw7"&gt;TMLR&lt;/a&gt;.
&lt;a href="https://arxiv.org/abs/2206.11736"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects of varying size within the complex 3D scene that may impact gameplay. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. Further multimodal novelty detection experiments suggest that methods that fuse both visual and symbolic information can improve time until detection as well as overall discrimination. Finally, our evaluation of recent generalized category discovery methods suggests that adapting to new imbalanced categories in complex scenes remains an exciting open problem.&lt;/p&gt;</content><category term="papers"></category><category term="news"></category></entry><entry><title>Evaluating the Use of Reconstruction Error for Novelty Localization</title><link href="https://patrickfeeney.github.io/evaluating-the-use-of-reconstruction-error-for-novelty-localization.html" rel="alternate"></link><published>2021-07-28T10:00:00-05:00</published><updated>2021-07-28T10:00:00-05:00</updated><author><name>Patrick Feeney</name></author><id>tag:patrickfeeney.github.io,2021-07-28:/evaluating-the-use-of-reconstruction-error-for-novelty-localization.html</id><summary type="html">&lt;p&gt;Published in &lt;a href="https://icml.cc/virtual/2021/workshop/8374"&gt;ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning&lt;/a&gt;.
&lt;a href="https://arxiv.org/abs/2107.13379"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The pixelwise reconstruction error of deep autoencoders is often utilized for image novelty detection and localization under the assumption that pixels with high error indicate which parts of the input image are unfamiliar and therefore likely …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Published in &lt;a href="https://icml.cc/virtual/2021/workshop/8374"&gt;ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning&lt;/a&gt;.
&lt;a href="https://arxiv.org/abs/2107.13379"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The pixelwise reconstruction error of deep autoencoders is often utilized for image novelty detection and localization under the assumption that pixels with high error indicate which parts of the input image are unfamiliar and therefore likely to be novel. This assumed correlation between pixels with high reconstruction error and novel regions of input images has not been verified and may limit the accuracy of these methods. In this paper we utilize saliency maps to evaluate whether this correlation exists. Saliency maps reveal directly how much a change in each input pixel would affect reconstruction loss, while each pixel's reconstruction error may be attributed to many input pixels when layers are fully connected. We compare saliency maps to reconstruction error maps via qualitative visualizations as well as quantitative correspondence between the top K elements of the maps for both novel and normal images. Our results indicate that reconstruction error maps do not closely correlate with the importance of pixels in the input images, making them insufficient for novelty localization.&lt;/p&gt;</content><category term="papers"></category><category term="news"></category></entry><entry><title>4-d Scene Alignment in Surveillance Video</title><link href="https://patrickfeeney.github.io/4-d-scene-alignment-in-surveillance-video.html" rel="alternate"></link><published>2019-10-15T10:00:00-05:00</published><updated>2019-10-15T10:00:00-05:00</updated><author><name>Patrick Feeney</name></author><id>tag:patrickfeeney.github.io,2019-10-15:/4-d-scene-alignment-in-surveillance-video.html</id><summary type="html">&lt;p&gt;Published in &lt;a href="https://ieeexplore.ieee.org/abstract/document/9174582"&gt;2019 IEEE Applied Imagery Pattern Recognition Workshop&lt;/a&gt;.
&lt;a href="https://arxiv.org/abs/1906.01675"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Designing robust activity detectors for fixed camera surveillance video requires knowledge of the 3-D scene. This paper presents an automatic camera calibration process that provides a mechanism to reason about the spatial proximity between objects at different times. It …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Published in &lt;a href="https://ieeexplore.ieee.org/abstract/document/9174582"&gt;2019 IEEE Applied Imagery Pattern Recognition Workshop&lt;/a&gt;.
&lt;a href="https://arxiv.org/abs/1906.01675"&gt;arXiv version&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Designing robust activity detectors for fixed camera surveillance video requires knowledge of the 3-D scene. This paper presents an automatic camera calibration process that provides a mechanism to reason about the spatial proximity between objects at different times. It combines a CNN-based camera pose estimator with a vertical scale provided by pedestrian observations to establish the 4-D scene geometry. Unlike some previous methods, the people do not need to be tracked nor do the head and feet need to be explicitly detected. It is robust to individual height variations and camera parameter estimation errors.&lt;/p&gt;</content><category term="papers"></category><category term="news"></category></entry></feed>